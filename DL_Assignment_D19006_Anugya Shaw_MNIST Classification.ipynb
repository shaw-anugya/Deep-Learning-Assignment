{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Anugya Shaw <br>\n",
    "**Roll no**: D19006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feed forward network using MNIST Classification dataset and experiment on its parameters using different optimizers to achieve best accuracy with minimum and maximum number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data shape:  (42000, 785)\n",
      "Test Data shape:  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Importing Training and Test data\n",
    "train=pd.read_csv('C:/Users/Anugya/Downloads/digit-recognizer/train.csv')\n",
    "test=pd.read_csv('C:/Users/Anugya/Downloads/digit-recognizer/test.csv')\n",
    "print('Training Data shape: ',train.shape)\n",
    "print('Test Data shape: ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train.drop(\"label\",axis=1)\n",
    "y=np.array(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of Train-Set 33600 , len of Test-Set 8400\n"
     ]
    }
   ],
   "source": [
    "# Convert Data to Tensor\n",
    "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\n",
    "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "\n",
    "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "valid_no  = int(0.2 * len(myDataset))\n",
    "\n",
    "# Divide the data into trainset and testset\n",
    "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
    "print(f\"len of Train-Set {len(trainSet)} , len of Test-Set {len(testSet)}\")\n",
    "\n",
    "\n",
    "# Load Data in memory\n",
    "train_loader  = DataLoader(trainSet , batch_size=64 ,shuffle=True) \n",
    "test_loader  = DataLoader(testSet , batch_size=64 ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (fc1): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (fc2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (fc3): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (fc4): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (fc5): Linear(in_features=25, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 25)\n",
    "        self.fc2 = nn.Linear(25, 25)\n",
    "        self.fc3 = nn.Linear(25, 25)\n",
    "        self.fc4 = nn.Linear(25, 25)\n",
    "        self.fc5 = nn.Linear(25, 10)\n",
    "\n",
    "        # Dropout module with drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "\n",
    "        # No dropout at output\n",
    "        x = F.log_softmax(self.fc5(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "print(model)\n",
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9,nesterov=True)\n",
    "#optimizer = optim.SGD(model.parameters(),lr=0.2, momentum=0.9,weight_decay=1e-68nesterov=True)\n",
    "#optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 1.772..  Test Loss: 0.768..  Test Accuracy: 0.813\n",
      "Epoch: 2/10..  Training Loss: 0.843..  Test Loss: 0.435..  Test Accuracy: 0.892\n",
      "Epoch: 3/10..  Training Loss: 0.655..  Test Loss: 0.370..  Test Accuracy: 0.911\n",
      "Epoch: 4/10..  Training Loss: 0.568..  Test Loss: 0.325..  Test Accuracy: 0.914\n",
      "Epoch: 5/10..  Training Loss: 0.517..  Test Loss: 0.291..  Test Accuracy: 0.922\n",
      "Epoch: 6/10..  Training Loss: 0.493..  Test Loss: 0.285..  Test Accuracy: 0.924\n",
      "Epoch: 7/10..  Training Loss: 0.466..  Test Loss: 0.267..  Test Accuracy: 0.927\n",
      "Epoch: 8/10..  Training Loss: 0.445..  Test Loss: 0.272..  Test Accuracy: 0.927\n",
      "Epoch: 9/10..  Training Loss: 0.433..  Test Loss: 0.245..  Test Accuracy: 0.933\n",
      "Epoch: 10/10..  Training Loss: 0.424..  Test Loss: 0.260..  Test Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation details by changing hyperparatemeters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Optimizer: SGD, learning rate = 0.002, momentum = 0.9, nesterov = True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (fc1): Linear(in_features=784, out_features=240, bias=True)\n",
      "  (fc2): Linear(in_features=240, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (fc4): Linear(in_features=160, out_features=120, bias=True)\n",
      "  (fc5): Linear(in_features=120, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 240)\n",
    "        self.fc2 = nn.Linear(240, 200)\n",
    "        self.fc3 = nn.Linear(200, 160)\n",
    "        self.fc4 = nn.Linear(160, 120)\n",
    "        self.fc5 = nn.Linear(120, 10)\n",
    "\n",
    "        # Dropout module with drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "\n",
    "        # No dropout at output\n",
    "        x = F.log_softmax(self.fc5(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "print(model)\n",
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.002, momentum=0.9,nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 0.195..  Test Loss: 0.150..  Test Accuracy: 0.959\n",
      "Epoch: 2/10..  Training Loss: 0.176..  Test Loss: 0.139..  Test Accuracy: 0.961\n",
      "Epoch: 3/10..  Training Loss: 0.160..  Test Loss: 0.132..  Test Accuracy: 0.963\n",
      "Epoch: 4/10..  Training Loss: 0.147..  Test Loss: 0.126..  Test Accuracy: 0.964\n",
      "Epoch: 5/10..  Training Loss: 0.137..  Test Loss: 0.119..  Test Accuracy: 0.965\n",
      "Epoch: 6/10..  Training Loss: 0.128..  Test Loss: 0.117..  Test Accuracy: 0.967\n",
      "Epoch: 7/10..  Training Loss: 0.118..  Test Loss: 0.111..  Test Accuracy: 0.969\n",
      "Epoch: 8/10..  Training Loss: 0.113..  Test Loss: 0.108..  Test Accuracy: 0.971\n",
      "Epoch: 9/10..  Training Loss: 0.104..  Test Loss: 0.108..  Test Accuracy: 0.970\n",
      "Epoch: 10/10..  Training Loss: 0.094..  Test Loss: 0.106..  Test Accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an accuracy of 0.971 we get number of parameters as 288560."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Optimizer: Adam, learning rate = 0.001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=12, bias=True)\n",
      "  (fc3): Linear(in_features=12, out_features=24, bias=True)\n",
      "  (fc4): Linear(in_features=24, out_features=20, bias=True)\n",
      "  (fc5): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 50)\n",
    "        self.fc2 = nn.Linear(50, 12)\n",
    "        self.fc3 = nn.Linear(12, 24)\n",
    "        self.fc4 = nn.Linear(24, 20)\n",
    "        self.fc5 = nn.Linear(20, 10)\n",
    "\n",
    "        # Dropout module with drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "\n",
    "        # No dropout at output\n",
    "        x = F.log_softmax(self.fc5(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "print(model)\n",
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 1.339..  Test Loss: 0.588..  Test Accuracy: 0.853\n",
      "Epoch: 2/10..  Training Loss: 0.785..  Test Loss: 0.375..  Test Accuracy: 0.900\n",
      "Epoch: 3/10..  Training Loss: 0.637..  Test Loss: 0.303..  Test Accuracy: 0.920\n",
      "Epoch: 4/10..  Training Loss: 0.565..  Test Loss: 0.271..  Test Accuracy: 0.926\n",
      "Epoch: 5/10..  Training Loss: 0.506..  Test Loss: 0.250..  Test Accuracy: 0.936\n",
      "Epoch: 6/10..  Training Loss: 0.470..  Test Loss: 0.232..  Test Accuracy: 0.937\n",
      "Epoch: 7/10..  Training Loss: 0.451..  Test Loss: 0.217..  Test Accuracy: 0.944\n",
      "Epoch: 8/10..  Training Loss: 0.427..  Test Loss: 0.220..  Test Accuracy: 0.943\n",
      "Epoch: 9/10..  Training Loss: 0.406..  Test Loss: 0.213..  Test Accuracy: 0.948\n",
      "Epoch: 10/10..  Training Loss: 0.396..  Test Loss: 0.208..  Test Accuracy: 0.946\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above model we get an accuracy of 0.946 and number of parameters as 40768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
